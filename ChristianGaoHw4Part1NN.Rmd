---
title: "ChristianGao418Hw4"
author: "Christian Gao"
date: "6/7/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Sentiment Analysis Using Neural Networks

#Data Cleaning
We start by cleaning the raw tweets. In addition to removing many symbols and capitalization from the previous study, we furthur simplify by removing all consecutive duplicate characters as well as remove any non ASCII characters. this is to limit the number of possible factors so its easier to train a model.


```{r cleaning raw data, echo = TRUE , message=FALSE}
library(keras)
library(magrittr)
library(data.table)
library(sfsmisc)

sentiment_df<-fread("data/sentiment_raw.csv")
sentiment_df<-sentiment_df[1:10000]
sentiment_df$ascii<-iconv(sentiment_df$JustText, "latin1", "ASCII", sub="")
sentiment_df$no_repeats<-gsub("([[:alpha:]])\\1{2,}", "\\1", sentiment_df$ascii)
sentiment_df$no_repeats<-gsub("(?<=[\\s])\\s*|^\\s+|\\s+$","",perl=TRUE,sentiment_df$no_repeats)
sentiment_df<-sentiment_df[sapply(gregexpr("\\W+", sentiment_df$no_repeats), length) >1,]
```

### Finding All Unique words for features

We then use unix command to order aggregate a list of all unique words and then read that back into R.

```{r unique words, echo= TRUE, message=FALSE}
sentiment_df_small<-sentiment_df
writeLines(sentiment_df_small$no_repeats,"data/smalltest.txt")
system("grep -o -E '\\w+' data/smalltest.txt | sort -u -f > data/wordlist.txt")
factor_list<-factor(readLines(con="./data/wordlist.txt"))
text_raw_list<-strsplit(sentiment_df_small$no_repeats,split = " ")

```

### Substituting All Words for Their Corresponding Factor Level To Input Into NN

We take the list of unique words and convert them to factors. We then go through our training data and associate each word with its correspoding factor. For example a sentence such as "The dog ate the cat" would map to [3,68,124,3,473]. These factor level are going to be the inputs for the first layer of the neural network.

```{r factor substitution, echo = FALSE , message=FALSE, include = FALSE}

get_training<-function(string_in,levels){
  y2<-factor(string_in,levels = levels); 
  result<-unclass(y2) %>% as.numeric 
  if(NA %in% result){
    print(string_in)
    print(result)
  }
  result
}

nn_predictors<-lapply(text_raw_list,get_training,levels = factor_list)

training_index<-sample(1:length(nn_predictors),length(nn_predictors)*.75)
x_train<- nn_predictors[training_index]
x_test <- nn_predictors[-training_index]

y_train<- sentiment_df_small$Sentiment[training_index]
y_test <- sentiment_df_small$Sentiment[-training_index]

cat("Training Set Response Example:")
head(y_train,2)
cat("Training Set Predictor Example:")
head(x_train,2)

```

###Training The Neural Network

```{r nn training, echo = FALSE , message=FALSE, include=FALSE, cache=FALSE}
max_features <- length(factor_list)
maxlen <- 40  # cut texts after this number of words
batch_size <- 128

print('Loading data...\n')
cat(length(x_train), 'train sequences\n')
cat(length(x_test), 'test sequences\n')

print('Pad sequences (samples x time)\n')
x_train <- pad_sequences(x_train, maxlen = maxlen)
x_test <- pad_sequences(x_test, maxlen = maxlen)
cat('x_train shape:', dim(x_train), '\n')
cat('x_test shape:', dim(x_test), '\n')

print('Build model...\n')
# model <- keras_model_sequential()
# model %>%
#   layer_embedding(input_dim = max_features, output_dim = 128) %>%
#   layer_lstm(units = 64, dropout = 0.2, recurrent_dropout = 0.2) %>%
#   layer_dense(units = 1, activation = 'sigmoid')
# 
# #Model Settings
# model %>% compile(
#   loss = 'binary_crossentropy',
#   optimizer = 'adam',
#   metrics = c('accuracy')
# )
# 
print('Train...\n')
# model %>% fit(
#   x_train, y_train,
#   batch_size = batch_size,
#   epochs = 1,
#   validation_data = list(x_test, y_test)
# )
# save_model_hdf5(model, filepath = "data/nn_small_model", overwrite = TRUE,
#                 include_optimizer = TRUE)
# 
model<-load_model_hdf5(filepath="data/nn_small_model",custom = NULL)
# 
scores <- model %>% evaluate(
  x_test, y_test,
  batch_size = batch_size
)
```
###Results

```{r nn results, echo = FALSE , message=FALSE}

#Results

model
cat('Test score:', scores[[1]])
cat('Test accuracy', scores[[2]])

predictions <-predict_classes(model,x_test)
probs <-predict_proba(model,x_test)

#Confusion Matrix
table(y_test, predictions)

#AUC
generate_auc<-function(probs,predictionsm,dens){
  
  getTPR<-function(y_test,predictions){
    
    rates<-table(y_test, predictions)%>%as.data.frame
    TP<-(rates%>%subset(y_test == 0)%>%subset(predictions == 0))$Freq
    if(length(TP)==0)
      TP = 0
    TN<-(rates%>%subset(y_test == 0)%>%subset(predictions == 1))$Freq
    if(length(TN)==0)
      TN = 0
    return(TP/(TP+TN))
  }
  
  getFPR<-function(y_test, predictions){
    
    rates<-table(y_test, predictions)%>%as.data.frame
    FP<-(rates%>%subset(y_test == 1)%>%subset(predictions == 0))$Freq
    if(length(FP)==0)
      FP = 0
    FN<-(rates%>%subset(y_test == 1)%>%subset(predictions == 1))$Freq
    if(length(FN)==0)
      FN = 0
    return(FP/(FP+FN))
  }

  pred_list = lapply(seq(-.5,.5,dens),function(addit){round(probs+addit)})
                                                                  
  TPR_list = sapply(X = pred_list ,FUN=getTPR, y_test =y_test)
  FPR_list = sapply(X = pred_list ,FUN=getFPR, y_test =y_test)
  
  plot(FPR_list,TPR_list, main = "NN ROC curve" , xlab = "False Positive", ylab = "TRUE positive", col = "blue")
  
  auc = integrate.xy(FPR_list,TPR_list)
  
  return(auc)
}
#
auc<-generate_auc(probs,predictions,.001)

cat("FINAL AUC: " ,auc)

```

###Conclusions For Neural Network

Looking at the final results, we can see that the neural network was able to out perform the GBM with its self generated features. We also observe that the neural network tends to do very well with positive tweets while GBM tends to do very well with negative tweets. We also note that since the Neural network was done on a GPU with a smaller dataset, the training time was alot faster. Perhapes next we we shall try an ensemble method to combine the two results into one model. 


